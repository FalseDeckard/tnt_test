# Search Engine TNT

Проект представляет собой поисковый движок с поддержкой различных методов поиска: векторного, текстового (BM25) и гибридного. Система разработана для эффективного поиска по русскоязычным документам с учетом семантики и точного соответствия.

## Архитектура

Проект реализован как веб-приложение на FastAPI с тремя основными методами поиска:
- Векторный поиск (semantic search)
- Текстовый поиск (BM25)
- Гибридный поиск (комбинация векторного и текстового)

### Структура проекта
```
tnt_test/
├── app/
│   ├── api/              # API endpoints
│   ├── core/             # Поисковые движки
│   ├── data/             # Модуль предобработки датасета и генерации эмбеддингов
│   ├── models/           # Pydantic модель
│   ├── templates/        # HTML шаблон
│   └── evaluation/       # Модуль оценки качества
├── data/
│   ├── processed/        # Обработанные данные
│   ├── evaluation/       # Отчет по качеству поисковика
│   └── raw/              # Сырые данные
├── Dockerfile
├── download_data.sh      #Скрипт для автоматической выгрузки сырых и предобработанных данных
├── requirements.txt
└── README.md
```

## Реализация поисковых методов

### 1. Векторный поиск

#### Выбор модели
Для векторного поиска используется модель `deepvk/USER-bge-m3`. Выбор обоснован следующими факторами:

1. **Специализация на русском языке**: Выбрана дообученная на русскоязычных корпусах модель bge-m3
2. **Семантическая точность**: Высокие результаты на бенчмарках для русского языка (https://huggingface.co/spaces/mteb/leaderboard, https://github.com/avidale/encodechka)
3. **Легковесность**: Модель весит всего 1.34 Gb
4. **Эффективность**: Быстрая генерация эмбеддингов благодаря оптимизированной архитектуре

#### Реализация
- Использование FAISS для индексации и поиска
- Нормализация векторов для косинусного сходства
- Поддержка батчей для оптимизации производительности
- Кэширование модели для экономии памяти

### 2. Текстовый поиск (BM25)

#### Особенности реализации
- Использование BM25Okapi с оптимизированными параметрами
- Предварительная обработка текста:
  - Лемматизация с помощью pymorphy3
  - Удаление стоп-слов
  - Нормализация текста
- Кэширование обработанных запросов

### 3. Гибридный поиск

#### Алгоритм объединения результатов
1. **Взвешенное объединение**:
   ```python
   final_score = bm25_score * weight_bm25 + vector_score * weight_vector
   ```
   где веса настраиваются динамически (по умолчанию 0.5/0.5)

2. **Нормализация скоров**:
   - BM25 скоры нормализуются к диапазону [0, 1]
   - Векторные скоры уже нормализованы (косинусное сходство)

3. **Ранжирование**:
   - Результаты сортируются по комбинированному скору
   - Возвращаются top-k документов
   
## Датасет

### Общая информация
- Количество документов: 6793
- Тип данных: Новостные статьи на русском языке
- Средняя длина основного текста: ~767 токенов

### Структура данных
Каждый документ после обработки содержит следующие поля:
```json
{
    "title": "Заголовок статьи",
    "summary": "Краткое содержание статьи",
    "url": "URL источника",
    "date": "Дата публикации",
    "text": "Полный текст статьи",
    "text_processed": "Предобработанный текст для поиска"
}
```

### Предобработка данных

1. **Текстовая предобработка**:
   - Лемматизация с помощью pymorphy3
   - Удаление стоп-слов
   - Нормализация текста (приведение к нижнему регистру, удаление спецсимволов)

2. **Подготовка данных**:
   - Создание FAISS индекса для векторного поиска
   - Генерация и сохранение эмбеддингов
   - Подготовка документов для BM25

## API и Интерфейс

### REST API
- POST `/api/search/`: Основной эндпоинт поиска
- Поддержка множественных запросов
- Настройка весов для гибридного поиска
- Пакетная обработка запросов

### Веб-интерфейс
- Интуитивный интерфейс для тестирования
- Настройка параметров поиска
- Визуализация результатов и метрик

## Оценка качества

- Отчет находится по пути data/evaluation/search_evaluation_report_20250128_175139.txt.

## Особенности и ограничения

1. **Производительность**:
   - Кэширование модели и эмбеддингов
   - Пакетная обработка запросов
   - Оптимизация использования памяти

2. **Ограничения**:
   - Максимальное количество запросов в батче: 20
   - Максимальное количество возвращаемых результатов: 20

## Установка и запуск

### Через Docker

1. Запустите Docker

2. Создайте образ:
```bash
docker build -t search-engine .
```

3. Запустите контейнер:
```bash
docker run -p 8000:8000 search-engine
```

После запуска:
- Веб-интерфейс будет доступен по адресу: http://localhost:8000
- API документация: http://localhost:8000/api/docs
- Альтернативная документация: http://localhost:8000/api/redoc

### Структура Docker образа

- Базовый образ: `python:3.10-slim`
- Предустановленные компоненты:
  - Все необходимые Python пакеты из requirements.txt
  - Модель deepvk/USER-bge-m3 для векторного поиска
  - Сырые и предобработанные данные загружаются при старте через скрипт download_data.sh, чтобы избежать долгой обработки.

### Примечания по развертыванию

- Порт 8000 должен быть свободен на хост-машине
- При первом запуске будет загружена модель и необходимые данные


## Дальнейшие улучшения

1. Оптимизация батч-процессинга для векторного поиска
2. Реализация более сложных алгоритмов объединения результатов (Retriever + Reranker)
3. Составление эталонного датасета и вычисление Precision, Recall, NDGC - с текущим датасетом новостей это несколько затруднительно, поэтому для оценки были использованы косвенные методы (косинусное сходство, оценка bm25, взвешенная оценка).
4. Замена взвешенной оценки на RRF.
4. Улучшенный менеджмент данных.